import os
import logging
import time

from functools import lru_cache as lc
import prometheus_client as prom
import cvexporter.openshift_cluster as openshift_cluster
import cvexporter.quay_images as quay  # noqa: F401

from prometheus_client.core import REGISTRY, GaugeMetricFamily


DEFAULT_SKIP_NS = 'dedicated-admin, dedicated-reader, default,' \
                    'kube-public, kube-system, management-infra,' \
                    'openshift, openshift-config, openshift-console,' \
                    'openshift-infra, openshift-logging,' \
                    'openshift-metrics-server, openshift-monitoring,' \
                    'openshift-node, openshift-operator-lifecycle-manager,' \
                    'openshift-operators, openshift-sdn,' \
                    'openshift-web-console, ops-health-monitoring,' \
                    'openshift-psad'


TARGET_NS = os.getenv('TARGET_NS')
SKIP_NS = DEFAULT_SKIP_NS
LISTEN_PORT = int(os.getenv('LISTEN_PORT') or 8080)
POLL_INTERVAL = int(os.getenv('POLL_INTERVAL') or 30)

LOG_LEVEL = str(os.getenv('LOG_LEVEL', 'INFO'))


class CveMetrics(object):
    def collect(self):
        g = GaugeMetricFamily('container_vulnerabilities_total',
                              'Container Vulnerability Totals by Severity',
                              labels=['namespace',
                                      'saas_context',
                                      'saas_service',
                                      'container_name',
                                      'severity'])
        prom_data = metrics_cache()
        for ns, context, service, container, sev, vulncount in prom_data:
            g.add_metric([ns,
                         context,
                         service,
                         container,
                         sev], vulncount)
        yield g


@lc()
def collect_metrics():
    metric_data = []
    for ns, context, service, container, imageurl in \
            openshift_cluster.get_images(TARGET_NS, SKIP_NS):
        if quay.from_quay(imageurl):
            vulnerabilities = quay.get_vulnerabilities(imageurl)
            if vulnerabilities is not None:
                for sev in quay.severities():
                    metric_data.append((ns,
                                        context,
                                        service,
                                        container,
                                        sev,
                                        vulnerabilities[sev]))
        else:
            #  logging.info(f'(n:{ns}) {pod}/{container} is not sourced ' +
            #               ' from Quay.io')
            continue
    return metric_data


@lc()
def metrics_cache():
    return collect_metrics()


def balance_caches():
    logging.info('Quay Vulnerabilities {}'
                 .format(str(quay.wget_vulnerabilities.cache_info()))
                 )
    quay.wget_vulnerabilities.cache_clear()
    logging.info('Openshift Resources {}'
                 .format(str(
                  openshift_cluster.get_resources_by_kind.cache_info()))
                 )
    openshift_cluster.get_resources_by_kind.cache_clear()


if __name__ == '__main__':
    logging.basicConfig(format='%(levelname)s: %(message)s',
                        level=getattr(logging, LOG_LEVEL))
    prom.start_http_server(LISTEN_PORT)
    REGISTRY.register(CveMetrics())

    logging.info('Starting collection loop.')
    while True:
        collect_metrics.cache_clear()
        collect_metrics()
        metrics_cache.cache_clear()
        balance_caches()
        time.sleep(POLL_INTERVAL)
